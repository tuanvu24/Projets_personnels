{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993a2941-2091-4bfe-90bb-c4af72f2c93b",
   "metadata": {},
   "source": [
    "# Categorical Encodings\n",
    "advanced encodings to encode the categorical variables to improve the classifier model:\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- CatBoost Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfad756-70e3-4434-94f8-3e5b3c3c6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "clicks = pd.read_parquet('dataset/baseline_data.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b87708b2-3189-488b-a5a8-ff860c28dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "    \"\"\"Splits a dataframe into train, validation, and test sets.\n",
    "\n",
    "    First, orders by the column 'click_time'. Set the size of the \n",
    "    validation and test sets with the valid_fraction keyword argument.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test=None, feature_cols=None):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                           'is_attributed', 'day', 'hour', 'minute', 'second'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    num_round = 1000\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    callbacks=[\n",
    "                    lgb.early_stopping(stopping_rounds=20),   \n",
    "                    lgb.log_evaluation(period=0)])\n",
    "    \n",
    "    \n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
    "    print(f\"Validation AUC score: {valid_score}\")\n",
    "    \n",
    "    if test is not None: \n",
    "        test_pred = bst.predict(test[feature_cols])\n",
    "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
    "        return bst, valid_score, test_score\n",
    "    else:\n",
    "        return bst, valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ad33796-6951-46c9-9068-38e9f14784b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model\n",
      "[LightGBM] [Info] Number of positive: 363974, number of negative: 1476475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 1840449, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.197764 -> initscore=-1.400330\n",
      "[LightGBM] [Info] Start training from score -1.400330\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's auc: 0.961874\n",
      "Validation AUC score: 0.9618737977262175\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline model\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f675b-35d8-4dc5-bd51-d374aa5b5952",
   "metadata": {},
   "source": [
    "### 1) Count encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b55fd457-5a9d-4f18-8a8e-1160ceb54b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a2100fe-4a5b-47e2-80a1-7ba0cd8c8996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27226</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:13:23</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110007</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-06 15:41:07</td>\n",
       "      <td>2017-11-07 08:17:19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>2017-11-06 15:42:32</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76270</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:56:17</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57862</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>2017-11-06 15:57:01</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840445</th>\n",
       "      <td>11718</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-09 04:50:14</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840449</th>\n",
       "      <td>32849</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>2017-11-09 04:50:14</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840446</th>\n",
       "      <td>249422</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>103</td>\n",
       "      <td>2017-11-09 04:50:14</td>\n",
       "      <td>2017-11-09 04:53:15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840443</th>\n",
       "      <td>232256</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>59</td>\n",
       "      <td>2017-11-09 04:50:14</td>\n",
       "      <td>2017-11-09 04:50:59</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840442</th>\n",
       "      <td>227929</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-11-09 04:50:14</td>\n",
       "      <td>2017-11-09 04:50:48</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1840449 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ip  app  device  os  channel          click_time  \\\n",
       "0         27226    3       1  13      120 2017-11-06 15:13:23   \n",
       "1        110007   35       1  13       10 2017-11-06 15:41:07   \n",
       "2          1047    6       1  13      157 2017-11-06 15:42:32   \n",
       "3         76270    3       1  13      120 2017-11-06 15:56:17   \n",
       "4         57862    3       1  13      120 2017-11-06 15:57:01   \n",
       "...         ...  ...     ...  ..      ...                 ...   \n",
       "1840445   11718   18       1  17       26 2017-11-09 04:50:14   \n",
       "1840449   32849   15       1  19       75 2017-11-09 04:50:14   \n",
       "1840446  249422   48       1  19      103 2017-11-09 04:50:14   \n",
       "1840443  232256   19       6  21       59 2017-11-09 04:50:14   \n",
       "1840442  227929   10       1  46       20 2017-11-09 04:50:14   \n",
       "\n",
       "             attributed_time  is_attributed  day  hour  minute  second  \n",
       "0                       None              0    6    15      13      23  \n",
       "1        2017-11-07 08:17:19              1    6    15      41       7  \n",
       "2                       None              0    6    15      42      32  \n",
       "3                       None              0    6    15      56      17  \n",
       "4                       None              0    6    15      57       1  \n",
       "...                      ...            ...  ...   ...     ...     ...  \n",
       "1840445                 None              0    9     4      50      14  \n",
       "1840449                 None              0    9     4      50      14  \n",
       "1840446  2017-11-09 04:53:15              1    9     4      50      14  \n",
       "1840443  2017-11-09 04:50:59              1    9     4      50      14  \n",
       "1840442  2017-11-09 04:50:48              1    9     4      50      14  \n",
       "\n",
       "[1840449 rows x 12 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44f70e63-cd92-4a02-815b-ad28021e33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count encoder\n",
    "count_enc = ce.CountEncoder(cols=cat_features)\n",
    "\n",
    "# Learn encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_counts'))\n",
    "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_counts'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71bcfc8c-1352-4756-b5ec-f9d2daba92da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 363974, number of negative: 1476475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 1840449, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.197764 -> initscore=-1.400330\n",
      "[LightGBM] [Info] Start training from score -1.400330\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid_0's auc: 0.964757\n",
      "Validation AUC score: 0.9647570268628647\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the encoded datasets\n",
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63499807-ae44-403e-84c4-9d86963e16ab",
   "metadata": {},
   "source": [
    "### 2) Target encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7b7ff9b-9bec-4b90-899e-67af33e6d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "    \n",
    "# Learn encoding from the training set. Use the 'is_attributed' column as the target.\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73aad59b-2eba-427e-914c-ca975b1a1fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 363974, number of negative: 1476475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1840449, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.197764 -> initscore=-1.400330\n",
      "[LightGBM] [Info] Start training from score -1.400330\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.946925\n",
      "Validation AUC score: 0.9469248136931894\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a126aa0-77e1-4b36-9168-e4c37741a0ad",
   "metadata": {},
   "source": [
    "### 3) CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3009876-30ee-4498-80d8-6fa17c0f9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove IP from the encoded features\n",
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the CatBoost encoder\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
    "\n",
    "# Learn encoding from the training set\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3f17775-04e8-4685-88af-fc57fb2c9497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 363974, number of negative: 1476475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1840449, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.197764 -> initscore=-1.400330\n",
      "[LightGBM] [Info] Start training from score -1.400330\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.962447\n",
      "Validation AUC score: 0.9624474042209968\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
